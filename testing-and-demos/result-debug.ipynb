{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating quiz, please wait...\n",
      "Quiz generated successfully!\n",
      "{\n",
      "    \"query\": \"\\nYou are a teacher and need to generate a quiz for your class based on the provided document.\\n\\nThe quiz should contain 5 questions.\\n\\nEach question should have 4 options, out of which only one is correct.\\n\\nFormat the output as a JSON object with the following structure:\\n\\n{\\n    \\\"quiz_id\\\": ,\\n    \\\"title\\\": \\\"\\\",\\n    \\\"desc\\\": \\\"Ml test\\\",\\n    \\\"src_doc\\\": \\\"Uploaded Document\\\",\\n    \\\"questions\\\": [\\n        {\\n            \\\"question_id\\\": 1,\\n            \\\"question\\\": \\\"\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False}\\n            ]\\n        },\\n        ...\\n    ]\\n}\\n\\nEnsure the questions are relevant to the content of the uploaded document.\\n        \",\n",
      "    \"result\": \"{\\n    \\\"quiz_id\\\": 101,\\n    \\\"title\\\": \\\"Machine Learning Techniques Quiz\\\",\\n    \\\"desc\\\": \\\"ML test\\\",\\n    \\\"src_doc\\\": \\\"Uploaded Document\\\",\\n    \\\"questions\\\": [\\n        {\\n            \\\"question_id\\\": 1,\\n            \\\"question\\\": \\\"What is 'Bag of Words' in the context of machine learning?\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"A method to represent text as a set of words, ignoring grammar and word order\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"A method to count the words in a text, considering the grammar\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"A method of storing words in a data structure\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"A technique of assigning weights to words based on their importance\\\", \\\"is_correct\\\": False}\\n            ]\\n        },\\n        {\\n            \\\"question_id\\\": 2,\\n            \\\"question\\\": \\\"What does TF-IDF stand for?\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"Term Frequency-Inverse Document Frequency\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"Total Frequency-Internal Document Frequency\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"Term Factor-Inverse Data Frequency\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"Total Factor-Internal Data Frequency\\\", \\\"is_correct\\\": False}\\n            ]\\n        },\\n        {\\n            \\\"question_id\\\": 3,\\n            \\\"question\\\": \\\"What is an example of Text Classification task in NLP?\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"Categorizing a movie review as positive or negative\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"Translating an English sentence to French\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"Summarizing a long news article into a few sentences\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"Counting the frequency of words in a document\\\", \\\"is_correct\\\": False}\\n            ]\\n        },\\n        {\\n            \\\"question_id\\\": 4,\\n            \\\"question\\\": \\\"How can missing data be handled in machine learning models?\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"Through Imputation or Dropping the data points\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"By ignoring the missing data\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"By replacing the missing data with random values\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"By assigning a fixed value to all missing data\\\", \\\"is_correct\\\": False}\\n            ]\\n        },\\n        {\\n            \\\"question_id\\\": 5,\\n            \\\"question\\\": \\\"What are outliers in the context of machine learning?\\\",\\n            \\\"options\\\": [\\n                {\\\"option_text\\\": \\\"Extreme values that are very different from the rest of the data\\\", \\\"is_correct\\\": True},\\n                {\\\"option_text\\\": \\\"The most common values in the data\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"The average values in the data\\\", \\\"is_correct\\\": False},\\n                {\\\"option_text\\\": \\\"The missing values in the data\\\", \\\"is_correct\\\": False}\\n            ]\\n        }\\n    ]\\n}\"\n",
      "}\n",
      "An error occurred: 'dict' object has no attribute 'result'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Validation Models\n",
    "class OptionModel(BaseModel):\n",
    "    option_text: str\n",
    "    is_correct: bool\n",
    "\n",
    "class QuestionModel(BaseModel):\n",
    "    question_id: int\n",
    "    question_text: str\n",
    "    options: List[OptionModel]\n",
    "\n",
    "class QuizModel(BaseModel):\n",
    "    quiz_id: int\n",
    "    title: str\n",
    "    description: str\n",
    "    source_document: str\n",
    "    questions: List[QuestionModel]\n",
    "\n",
    "def validate_quiz_response(response: dict) -> int:\n",
    "    try:\n",
    "        quiz = QuizModel(**response)\n",
    "        print(\"Validation successful!\")\n",
    "        return 0\n",
    "    except ValidationError as e:\n",
    "        print(\"Validation error:\", e.json())\n",
    "        return 1\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating quiz, please wait...\n",
      "Quiz generated successfully!\n",
      "{\n",
      "    \"query\": \"\\nYou are a teacher and need to generate a quiz for your class based on the provided document.\\n\\nThe quiz should contain 5 questions.\\n\\nEach question should have 4 options, out of which only one is correct.\\n\\nFormat the output as a JSON object with the following structure:\\n\\n{\\n\\\"quiz_id\\\": ,\\n\\\"title\\\": \\\"\\\",\\n\\\"desc\\\": \\\"ML test\\\",\\n\\\"src_doc\\\": \\\"Uploaded Document\\\",\\n\\\"questions\\\": [\\n    {\\n        \\\"question_id\\\": 1,\\n        \\\"question\\\": \\\"\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"\\\", \\\"is_correct\\\": False}\\n        ]\\n    },\\n    ...\\n]\\n}\\n\\nEnsure the questions are relevant to the content of the uploaded document.\\n    \",\n",
      "    \"result\": \"{\\n\\\"quiz_id\\\": 1,\\n\\\"title\\\": \\\"Machine Learning Quiz\\\",\\n\\\"desc\\\": \\\"ML test\\\",\\n\\\"src_doc\\\": \\\"Uploaded Document\\\",\\n\\\"questions\\\": [\\n    {\\n        \\\"question_id\\\": 1,\\n        \\\"question\\\": \\\"What is a Bag of Words?\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"A method to represent text as a set of words, ignoring grammar and word order.\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"A technique to analyze sentiment in a piece of text.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"A machine learning model for text classification.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"A deep learning technique for text summarization.\\\", \\\"is_correct\\\": False}\\n        ]\\n    },\\n    {\\n        \\\"question_id\\\": 2,\\n        \\\"question\\\": \\\"What does TF-IDF stand for?\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"Term Frequency-Inverse Document Frequency\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"Text Frequency-Inverse Document Field\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"Term Field-Inverse Document Frequency\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"Text Field-Inverse Document Frequency\\\", \\\"is_correct\\\": False}\\n        ]\\n    },\\n    {\\n        \\\"question_id\\\": 3,\\n        \\\"question\\\": \\\"What is an example of a NLP task?\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"Translating an English sentence to French using tools like Google Translate.\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"Predicting stock prices based on historical data.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"Recognizing objects in an image.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"Identifying fraudulent credit card transactions.\\\", \\\"is_correct\\\": False}\\n        ]\\n    },\\n    {\\n        \\\"question_id\\\": 4,\\n        \\\"question\\\": \\\"What is Deep Learning?\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"A subset of machine learning that uses neural networks with many layers to model complex patterns in data.\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"A type of supervised learning algorithm.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"A technique for text summarization.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"A method for data preprocessing.\\\", \\\"is_correct\\\": False}\\n        ]\\n    },\\n    {\\n        \\\"question_id\\\": 5,\\n        \\\"question\\\": \\\"What is the importance of Data Preprocessing?\\\",\\n        \\\"options\\\": [\\n            {\\\"option_text\\\": \\\"It\\u2019s important to clean the data because real-world data is often incomplete, noisy, or inconsistent.\\\", \\\"is_correct\\\": True},\\n            {\\\"option_text\\\": \\\"It helps in visualizing the data.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"It aids in training the machine learning model faster.\\\", \\\"is_correct\\\": False},\\n            {\\\"option_text\\\": \\\"It is useful for feature extraction.\\\", \\\"is_correct\\\": False}\\n        ]\\n    }\\n]\\n}\"\n",
      "}\n",
      "An error occurred: 'dict' object has no attribute 'result'\n"
     ]
    }
   ],
   "source": [
    "num_questions = int(input(\"Enter number of questions (1-10): \"))\n",
    "test_description = input(\"Enter a short description of the test: \")\n",
    "difficulty = int(input(\"Enter difficulty level (1-3): \"))\n",
    "file_path = r'C:\\Users\\Advait Shinde\\AI-SmartClassroom\\Machine Learning Roadmap.pdf'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"File not found!\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Load and split document\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    if not docs:\n",
    "        print(\"Failed to extract content from the document.\")\n",
    "        \n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Vector Store\n",
    "    vector_store = FAISS.from_documents(splits, embeddings)\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=QuizModel)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a teacher and need to generate a quiz for your class based on the provided document.\n",
    "\n",
    "The quiz should contain {num_questions} questions.\n",
    "\n",
    "Each question should have 4 options, out of which only one is correct.\n",
    "\n",
    "Format the output as a JSON object with the following structure:\n",
    "\n",
    "{{\n",
    "\"quiz_id\": ,\n",
    "\"title\": \"\",\n",
    "\"desc\": \"{test_description}\",\n",
    "\"src_doc\": \"Uploaded Document\",\n",
    "\"questions\": [\n",
    "    {{\n",
    "        \"question_id\": 1,\n",
    "        \"question\": \"\",\n",
    "        \"options\": [\n",
    "            {{\"option_text\": \"\", \"is_correct\": True}},\n",
    "            {{\"option_text\": \"\", \"is_correct\": False}},\n",
    "            {{\"option_text\": \"\", \"is_correct\": False}},\n",
    "            {{\"option_text\": \"\", \"is_correct\": False}}\n",
    "        ]\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "}}\n",
    "\n",
    "Ensure the questions are relevant to the content of the uploaded document.\n",
    "    \"\"\"\n",
    "    \n",
    "    rag_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "    print(\"Generating quiz, please wait...\")\n",
    "    result = rag_chain.invoke(prompt)\n",
    "\n",
    "    if result:\n",
    "        print(\"Quiz generated successfully!\")\n",
    "        print(json.dumps(result, indent=4))\n",
    "\n",
    "        if validate_quiz_response(result.result):\n",
    "            print(\"Validation failed. Check the quiz structure.\")\n",
    "    else:\n",
    "        print(\"Failed to generate quiz. LLM returned an empty response.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '\\nYou are a teacher and need to generate a quiz for your class based on the provided document.\\n\\nThe quiz should contain 5 questions.\\n\\nEach question should have 4 options, out of which only one is correct.\\n\\nFormat the output as a JSON object with the following structure:\\n\\n{\\n\"quiz_id\": ,\\n\"title\": \"\",\\n\"desc\": \"ML test\",\\n\"src_doc\": \"Uploaded Document\",\\n\"questions\": [\\n    {\\n        \"question_id\": 1,\\n        \"question\": \"\",\\n        \"options\": [\\n            {\"option_text\": \"\", \"is_correct\": True},\\n            {\"option_text\": \"\", \"is_correct\": False},\\n            {\"option_text\": \"\", \"is_correct\": False},\\n            {\"option_text\": \"\", \"is_correct\": False}\\n        ]\\n    },\\n    ...\\n]\\n}\\n\\nEnsure the questions are relevant to the content of the uploaded document.\\n    ',\n",
       " 'result': '{\\n\"quiz_id\": 1,\\n\"title\": \"Machine Learning Quiz\",\\n\"desc\": \"ML test\",\\n\"src_doc\": \"Uploaded Document\",\\n\"questions\": [\\n    {\\n        \"question_id\": 1,\\n        \"question\": \"What is a Bag of Words?\",\\n        \"options\": [\\n            {\"option_text\": \"A method to represent text as a set of words, ignoring grammar and word order.\", \"is_correct\": True},\\n            {\"option_text\": \"A technique to analyze sentiment in a piece of text.\", \"is_correct\": False},\\n            {\"option_text\": \"A machine learning model for text classification.\", \"is_correct\": False},\\n            {\"option_text\": \"A deep learning technique for text summarization.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 2,\\n        \"question\": \"What does TF-IDF stand for?\",\\n        \"options\": [\\n            {\"option_text\": \"Term Frequency-Inverse Document Frequency\", \"is_correct\": True},\\n            {\"option_text\": \"Text Frequency-Inverse Document Field\", \"is_correct\": False},\\n            {\"option_text\": \"Term Field-Inverse Document Frequency\", \"is_correct\": False},\\n            {\"option_text\": \"Text Field-Inverse Document Frequency\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 3,\\n        \"question\": \"What is an example of a NLP task?\",\\n        \"options\": [\\n            {\"option_text\": \"Translating an English sentence to French using tools like Google Translate.\", \"is_correct\": True},\\n            {\"option_text\": \"Predicting stock prices based on historical data.\", \"is_correct\": False},\\n            {\"option_text\": \"Recognizing objects in an image.\", \"is_correct\": False},\\n            {\"option_text\": \"Identifying fraudulent credit card transactions.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 4,\\n        \"question\": \"What is Deep Learning?\",\\n        \"options\": [\\n            {\"option_text\": \"A subset of machine learning that uses neural networks with many layers to model complex patterns in data.\", \"is_correct\": True},\\n            {\"option_text\": \"A type of supervised learning algorithm.\", \"is_correct\": False},\\n            {\"option_text\": \"A technique for text summarization.\", \"is_correct\": False},\\n            {\"option_text\": \"A method for data preprocessing.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 5,\\n        \"question\": \"What is the importance of Data Preprocessing?\",\\n        \"options\": [\\n            {\"option_text\": \"It’s important to clean the data because real-world data is often incomplete, noisy, or inconsistent.\", \"is_correct\": True},\\n            {\"option_text\": \"It helps in visualizing the data.\", \"is_correct\": False},\\n            {\"option_text\": \"It aids in training the machine learning model faster.\", \"is_correct\": False},\\n            {\"option_text\": \"It is useful for feature extraction.\", \"is_correct\": False}\\n        ]\\n    }\\n]\\n}'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 11 column 125 (char 340)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m json_response \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m----> 2\u001b[0m parsed_result \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m parsed_result\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 11 column 125 (char 340)"
     ]
    }
   ],
   "source": [
    "json_response = result['result'].strip()\n",
    "parsed_result = json.loads(json_response)\n",
    "parsed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"quiz_id\": 1,\\n\"title\": \"Machine Learning Quiz\",\\n\"desc\": \"ML test\",\\n\"src_doc\": \"Uploaded Document\",\\n\"questions\": [\\n    {\\n        \"question_id\": 1,\\n        \"question\": \"What is a Bag of Words?\",\\n        \"options\": [\\n            {\"option_text\": \"A method to represent text as a set of words, ignoring grammar and word order.\", \"is_correct\": True},\\n            {\"option_text\": \"A technique to analyze sentiment in a piece of text.\", \"is_correct\": False},\\n            {\"option_text\": \"A machine learning model for text classification.\", \"is_correct\": False},\\n            {\"option_text\": \"A deep learning technique for text summarization.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 2,\\n        \"question\": \"What does TF-IDF stand for?\",\\n        \"options\": [\\n            {\"option_text\": \"Term Frequency-Inverse Document Frequency\", \"is_correct\": True},\\n            {\"option_text\": \"Text Frequency-Inverse Document Field\", \"is_correct\": False},\\n            {\"option_text\": \"Term Field-Inverse Document Frequency\", \"is_correct\": False},\\n            {\"option_text\": \"Text Field-Inverse Document Frequency\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 3,\\n        \"question\": \"What is an example of a NLP task?\",\\n        \"options\": [\\n            {\"option_text\": \"Translating an English sentence to French using tools like Google Translate.\", \"is_correct\": True},\\n            {\"option_text\": \"Predicting stock prices based on historical data.\", \"is_correct\": False},\\n            {\"option_text\": \"Recognizing objects in an image.\", \"is_correct\": False},\\n            {\"option_text\": \"Identifying fraudulent credit card transactions.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 4,\\n        \"question\": \"What is Deep Learning?\",\\n        \"options\": [\\n            {\"option_text\": \"A subset of machine learning that uses neural networks with many layers to model complex patterns in data.\", \"is_correct\": True},\\n            {\"option_text\": \"A type of supervised learning algorithm.\", \"is_correct\": False},\\n            {\"option_text\": \"A technique for text summarization.\", \"is_correct\": False},\\n            {\"option_text\": \"A method for data preprocessing.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 5,\\n        \"question\": \"What is the importance of Data Preprocessing?\",\\n        \"options\": [\\n            {\"option_text\": \"It’s important to clean the data because real-world data is often incomplete, noisy, or inconsistent.\", \"is_correct\": True},\\n            {\"option_text\": \"It helps in visualizing the data.\", \"is_correct\": False},\\n            {\"option_text\": \"It aids in training the machine learning model faster.\", \"is_correct\": False},\\n            {\"option_text\": \"It is useful for feature extraction.\", \"is_correct\": False}\\n        ]\\n    }\\n]\\n}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"quiz_id\": 1,\n",
      "\"title\": \"Machine Learning Quiz\",\n",
      "\"desc\": \"ML test\",\n",
      "\"src_doc\": \"Uploaded Document\",\n",
      "\"questions\": [\n",
      "    {\n",
      "        \"question_id\": 1,\n",
      "        \"question\": \"What is a Bag of Words?\",\n",
      "        \"options\": [\n",
      "            {\"option_text\": \"A method to represent text as a set of words, ignoring grammar and word order.\", \"is_correct\": True},\n",
      "            {\"option_text\": \"A technique to analyze sentiment in a piece of text.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"A machine learning model for text classification.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"A deep learning technique for text summarization.\", \"is_correct\": False}\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"question_id\": 2,\n",
      "        \"question\": \"What does TF-IDF stand for?\",\n",
      "        \"options\": [\n",
      "            {\"option_text\": \"Term Frequency-Inverse Document Frequency\", \"is_correct\": True},\n",
      "            {\"option_text\": \"Text Frequency-Inverse Document Field\", \"is_correct\": False},\n",
      "            {\"option_text\": \"Term Field-Inverse Document Frequency\", \"is_correct\": False},\n",
      "            {\"option_text\": \"Text Field-Inverse Document Frequency\", \"is_correct\": False}\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"question_id\": 3,\n",
      "        \"question\": \"What is an example of a NLP task?\",\n",
      "        \"options\": [\n",
      "            {\"option_text\": \"Translating an English sentence to French using tools like Google Translate.\", \"is_correct\": True},\n",
      "            {\"option_text\": \"Predicting stock prices based on historical data.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"Recognizing objects in an image.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"Identifying fraudulent credit card transactions.\", \"is_correct\": False}\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"question_id\": 4,\n",
      "        \"question\": \"What is Deep Learning?\",\n",
      "        \"options\": [\n",
      "            {\"option_text\": \"A subset of machine learning that uses neural networks with many layers to model complex patterns in data.\", \"is_correct\": True},\n",
      "            {\"option_text\": \"A type of supervised learning algorithm.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"A technique for text summarization.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"A method for data preprocessing.\", \"is_correct\": False}\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"question_id\": 5,\n",
      "        \"question\": \"What is the importance of Data Preprocessing?\",\n",
      "        \"options\": [\n",
      "            {\"option_text\": \"It's important to clean the data because real-world data is often incomplete, noisy, or inconsistent.\", \"is_correct\": True},\n",
      "            {\"option_text\": \"It helps in visualizing the data.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"It aids in training the machine learning model faster.\", \"is_correct\": False},\n",
      "            {\"option_text\": \"It is useful for feature extraction.\", \"is_correct\": False}\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"quiz_id\": 1,\\n\"title\": \"Machine Learning Quiz\",\\n\"desc\": \"ML test\",\\n\"src_doc\": \"Uploaded Document\",\\n\"questions\": [\\n    {\\n        \"question_id\": 1,\\n        \"question\": \"What is a Bag of Words?\",\\n        \"options\": [\\n            {\"option_text\": \"A method to represent text as a set of words, ignoring grammar and word order.\", \"is_correct\": True},\\n            {\"option_text\": \"A technique to analyze sentiment in a piece of text.\", \"is_correct\": False},\\n            {\"option_text\": \"A machine learning model for text classification.\", \"is_correct\": False},\\n            {\"option_text\": \"A deep learning technique for text summarization.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 2,\\n        \"question\": \"What does TF-IDF stand for?\",\\n        \"options\": [\\n            {\"option_text\": \"Term Frequency-Inverse Document Frequency\", \"is_correct\": True},\\n            {\"option_text\": \"Text Frequency-Inverse Document Field\", \"is_correct\": False},\\n            {\"option_text\": \"Term Field-Inverse Document Frequency\", \"is_correct\": False},\\n            {\"option_text\": \"Text Field-Inverse Document Frequency\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 3,\\n        \"question\": \"What is an example of a NLP task?\",\\n        \"options\": [\\n            {\"option_text\": \"Translating an English sentence to French using tools like Google Translate.\", \"is_correct\": True},\\n            {\"option_text\": \"Predicting stock prices based on historical data.\", \"is_correct\": False},\\n            {\"option_text\": \"Recognizing objects in an image.\", \"is_correct\": False},\\n            {\"option_text\": \"Identifying fraudulent credit card transactions.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 4,\\n        \"question\": \"What is Deep Learning?\",\\n        \"options\": [\\n            {\"option_text\": \"A subset of machine learning that uses neural networks with many layers to model complex patterns in data.\", \"is_correct\": True},\\n            {\"option_text\": \"A type of supervised learning algorithm.\", \"is_correct\": False},\\n            {\"option_text\": \"A technique for text summarization.\", \"is_correct\": False},\\n            {\"option_text\": \"A method for data preprocessing.\", \"is_correct\": False}\\n        ]\\n    },\\n    {\\n        \"question_id\": 5,\\n        \"question\": \"What is the importance of Data Preprocessing?\",\\n        \"options\": [\\n            {\"option_text\": \"It\\'s important to clean the data because real-world data is often incomplete, noisy, or inconsistent.\", \"is_correct\": True},\\n            {\"option_text\": \"It helps in visualizing the data.\", \"is_correct\": False},\\n            {\"option_text\": \"It aids in training the machine learning model faster.\", \"is_correct\": False},\\n            {\"option_text\": \"It is useful for feature extraction.\", \"is_correct\": False}\\n        ]\\n    }\\n]\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 11 column 125 (char 340)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     parsed_result \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     parsed_result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Already a dictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Advait Shinde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 11 column 125 (char 340)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
